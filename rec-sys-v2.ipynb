{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Alternating Least Squares (ALS) Recommender V1.0"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[],"source":["# import necessary libraries\n","from pyspark.sql import SparkSession\n","\n","# instantiate SparkSession object\n","# spark = SparkSession.builder.master('local').getOrCreate()\n","\n","spark = SparkSession\\\n","        .builder\\\n","        .appName('ALSExample').config('spark.driver.host', 'localhost')\\\n","        .getOrCreate()"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[],"source":["# read in the dataset into pyspark DataFrame\n","action_ratings = spark.read.csv('./data/ratings-v2.csv', header='true', inferSchema='true')"]},{"cell_type":"markdown","metadata":{},"source":["Check the data types of each of the columns to ensure that they are a type that makes sense given the column."]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[{"data":{"text/plain":["[('userId', 'int'),\n"," ('actionId', 'int'),\n"," ('rating', 'double'),\n"," ('timestamp', 'int')]"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["action_ratings.dtypes"]},{"cell_type":"markdown","metadata":{},"source":["We aren't going to need the timestamp, so we can go ahead and remove that column."]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[],"source":["action_ratings = action_ratings.drop('timestamp')"]},{"cell_type":"markdown","metadata":{},"source":["### Fitting the Alternating Least Squares Model"]},{"cell_type":"markdown","metadata":{},"source":["\n","* Import `ALS` from `pyspark.ml.recommendation` module \n","* Use the `.randomSplit()` method on the pyspark DataFrame to separate the dataset into training and test sets\n","* Fit the Alternating Least Squares Model to the training dataset. Make sure to set the `userCol`, `itemCol`, and `ratingCol` to the appropriate columns given this dataset. Then fit the data to the training set and assign it to a variable model  "]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[],"source":["from pyspark.ml.evaluation import RegressionEvaluator\n","\n","from pyspark.ml.recommendation import ALS\n","\n","# split into training and testing sets\n","(training, test) = action_ratings.randomSplit([0.8, 0.2])\n","\n","# Build the recommendation model using ALS on the training data\n","# Note we set cold start strategy to 'drop' to ensure we don't get NaN evaluation metrics\n","als = ALS(maxIter=5,rank=4, regParam=0.01, userCol='userId', itemCol='actionId', ratingCol='rating',\n","          coldStartStrategy='drop')\n","\n","# fit the ALS model to the training set\n","model = als.fit(training)"]},{"cell_type":"markdown","metadata":{},"source":["Now you've fit the model, and it's time to evaluate it to determine just how well it performed.\n","\n","* Import `RegressionEvalutor` from `pyspark.ml.evaluation` \n","* Generate predictions with your model for the test set by using the `.transform()` method on your ALS model \n","* Evaluate your model and print out the RMSE from your test set "]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Root-mean-square error = 0.9929050579482068\n"]}],"source":["# importing appropriate library\n","from pyspark.ml.evaluation import RegressionEvaluator\n","\n","# Evaluate the model by computing the RMSE on the test data\n","predictions = model.transform(test)\n","evaluator = RegressionEvaluator(metricName='rmse', labelCol='rating',\n","                                predictionCol='prediction')\n","rmse = evaluator.evaluate(predictions)\n","print('Root-mean-square error = ' + str(rmse))"]},{"cell_type":"markdown","metadata":{},"source":["### Cross-validation to Find the Optimal Model\n","\n","Find the optimal values for the parameters of the ALS model. Use the built-in `CrossValidator` in PySpark with a suitable param grid and determine the optimal model. Try with the parameters:\n","\n","* regularization = [0.01, 0.001, 0.1]\n","* rank = [4, 10, 50]\n"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"data":{"text/plain":["50"]},"execution_count":37,"metadata":{},"output_type":"execute_result"}],"source":["from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n","\n","# initialize the ALS model\n","als_model = ALS(userCol='userId', itemCol='actionId', \n","                ratingCol='rating', coldStartStrategy='drop')\n","\n","# create the parameter grid                 \n","params = ParamGridBuilder()\\\n","          .addGrid(als_model.regParam, [0.01, 0.001, 0.1])\\\n","          .addGrid(als_model.rank, [4, 10, 50]).build()\n","\n","\n","# instantiating crossvalidator estimator\n","cv = CrossValidator(estimator=als_model, estimatorParamMaps=params,evaluator=evaluator,parallelism=4)\n","best_model = cv.fit(action_ratings)    \n","\n","# We see the best model has a rank of 50, so we will use that in our future models with this dataset\n","best_model.bestModel.rank"]},{"cell_type":"markdown","metadata":{},"source":["## Getting Recommendations\n","\n","Now it's time to actually get some recommendations! The ALS model has built-in methods called `.recommendForUserSubset()` and `.recommendForAllUsers()`. We'll start off with using a subset of users. "]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[],"source":["users = action_ratings.select(als.getUserCol()).distinct().limit(1)\n","userSubsetRecs = model.recommendForUserSubset(users, 10)\n","recs = userSubsetRecs.take(1)"]},{"cell_type":"markdown","metadata":{},"source":["We can now see we have a list of rows with recommended items. Now try and get the name of the top recommended action by way of the function you just created, using number one item for this user."]},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[],"source":["# use indexing to obtain the action id of top predicted rated item\n","first_recommendation = recs[0]['recommendations'][0][0]"]},{"cell_type":"markdown","metadata":{},"source":["Of course, you can also make recommendations for everyone, although this will take longer. In the next line, we are creating an RDD with the top 5 recommendations for every user and then selecting one user to find out his predictions:"]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[{"data":{"text/plain":["[Row(userId=3, recommendations=[Row(actionId=72167, rating=7.379295825958252), Row(actionId=3142, rating=6.3740620613098145), Row(actionId=4663, rating=6.285203456878662), Row(actionId=1866, rating=6.064001083374023), Row(actionId=33830, rating=5.827307224273682)])]"]},"execution_count":40,"metadata":{},"output_type":"execute_result"}],"source":["recommendations = model.recommendForAllUsers(5)\n","recommendations.where(recommendations.userId == 3).collect()"]},{"cell_type":"markdown","metadata":{},"source":["### Getting Predictions for a New User\n","\n","Now, it's time to put together all that you've learned in this section to create a function that will take in a new user and some actions they've rated and then return $n$ number of highest recommended actions. This function will have multiple different steps to it:\n","\n","* Adding the new ratings into the DataFrame (hint: look into using the `.union()` method) \n","* Fitting the ALS model  \n","* Make recommendations for the user of choice \n","* Print out the names of the top $n$ recommendations in a reader-friendly manner \n","\n"]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[],"source":["def new_user_recs(user_id, new_ratings, rating_df, num_recs):\n","    # turn the new_recommendations list into a spark DataFrame\n","    new_user_ratings = spark.createDataFrame(new_ratings,rating_df.columns)\n","    \n","    # combine the new ratings df with the rating_df\n","    action_ratings_combined = rating_df.union(new_user_ratings)\n","    \n","    # split the dataframe into a train and test set\n","#     (training, test) = action_ratings_combined.randomSplit([0.8, 0.2],seed=0)\n","    \n","    # create an ALS model and fit it\n","    als = ALS(maxIter=5,rank=50, regParam=0.01, userCol=\"userId\", itemCol=\"actionId\", ratingCol=\"rating\",\n","          coldStartStrategy=\"drop\")\n","    model = als.fit(action_ratings_combined)\n","    \n","    # make recommendations for all users using the recommendForAllUsers method\n","    recommendations = model.recommendForAllUsers(num_recs)\n","    \n","    # get recommendations specifically for the new user that has been added to the DataFrame\n","    recs_for_user = recommendations.where(recommendations.userId == user_id).take(1)\n","    \n","    for ranking, (action_id, rating) in enumerate(recs_for_user[0]['recommendations']):\n","        action_string = action_id\n","        print('Recommendation {}: {}  | predicted score :{}'.format(ranking+1,action_string,rating))\n","        "]},{"cell_type":"code","execution_count":42,"metadata":{"scrolled":false},"outputs":[{"name":"stdout","output_type":"stream","text":["Recommendation 1: 318  | predicted score :5.573312759399414\n","Recommendation 2: 593  | predicted score :5.422237873077393\n","Recommendation 3: 1198  | predicted score :5.411786079406738\n","Recommendation 4: 356  | predicted score :5.4110493659973145\n","Recommendation 5: 1270  | predicted score :5.398866653442383\n","Recommendation 6: 919  | predicted score :5.389611721038818\n","Recommendation 7: 260  | predicted score :5.38344144821167\n","Recommendation 8: 58559  | predicted score :5.342963695526123\n","Recommendation 9: 7153  | predicted score :5.339134216308594\n","Recommendation 10: 4993  | predicted score :5.3378376960754395\n"]}],"source":["user_id = 100000\n","user_ratings_1 = [(user_id,3253,5),\n","                  (user_id,2459,5),\n","                  (user_id,2513,4),\n","                  (user_id,6502,5),\n","                  (user_id,1091,5),\n","                  (user_id,441,4)]\n","new_user_recs(user_id,\n","             new_ratings=user_ratings_1,\n","             rating_df=action_ratings,\n","             num_recs = 10)"]}],"metadata":{"kernelspec":{"display_name":"Python 3.9.1 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.1"},"vscode":{"interpreter":{"hash":"aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"}}},"nbformat":4,"nbformat_minor":2}
